{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy\n",
    "from cvxpy import *\n",
    "import email\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    dictionary = None\n",
    "    \n",
    "    #stripHeaders helper conjoining multiple substitutions into one regex\n",
    "    @staticmethod\n",
    "    def multiRegexSubstitute(regexArray, text, substitute = \"\"):\n",
    "        rules = \"|\".join(regexArray)\n",
    "        pattern = re.compile(rules)\n",
    "        return pattern.sub(substitute, text)\n",
    "    \n",
    "    #Parse the standard email structure into a plaintext (strip headers, footers and section separators)\n",
    "    @staticmethod  \n",
    "    def stripHeaders(mail):\n",
    "        text = \"\"\n",
    "        for msg in email.message_from_string(mail).walk():\n",
    "            try:\n",
    "                text += msg.get_payload() + \" \"\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        #REGEX diacritics removal\n",
    "        text = re.sub(\"<[^<>]*>\", \" \", text) #remove HTML/XML tags\n",
    "        \n",
    "        text = Parser.multiRegexSubstitute([\"\\.\", \"\\?\", \";\", \",\", \"\\\"\", \"'\", \"=\", \"#\", \"[0-9]\", \"\\*\", \"!\", \"%\"], text) # non-expanding substitutions\n",
    "        text = Parser.multiRegexSubstitute([\"-\", \"\\(\", \"\\)\", \"\\n\", \"\\t\", \"&nbsp\", \"_\", \"&\", \"$\", \"@\", \":\"], text, \" \") # expanding substitutions\n",
    "        \n",
    "        text = re.sub(\" +\" ,\" \", text) #finisher whitespace removal\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "    #Translate a given email according into a word vector according to the preset dictionary\n",
    "    def parseEmail(self, mail):\n",
    "        parsedData = [0] * len(self.dictionary)\n",
    "        plaintext = Parser.stripHeaders(mail).split(\" \")\n",
    "        for x in plaintext:\n",
    "            if x in self.dictionary:\n",
    "                parsedData[self.dictionary.index(x)] += 1\n",
    "        return parsedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FilterSPAM:\n",
    "    a = None\n",
    "    b = None\n",
    "    \n",
    "    #CVXPY convex optimization solver, given vectorized emailes it tries to find optimal parameter values for logistic regression curve.\n",
    "    @staticmethod\n",
    "    def getModelParams(data, labels, size):\n",
    "        a = Variable(size, 1)\n",
    "        b = Variable()\n",
    "        spam = labels.index(False)\n",
    "        \n",
    "        testing = numpy.zeros((len(data), 1))\n",
    "        for i in range(len(labels)):\n",
    "            if not labels[i]:\n",
    "                break\n",
    "            testing[i, 0] = 1\n",
    "            \n",
    "        logLogistic = sum([logistic(data[i] * a + b) for i in range(len(data))])\n",
    "        positive = testing.T * data * a  + b * spam\n",
    "        problem = Problem(Maximize(positive - logLogistic))\n",
    "        \n",
    "        result = problem.solve()    \n",
    "        return a.value, b.value\n",
    "    \n",
    "    #Classify sample\n",
    "    def evaluate(self, sample):\n",
    "        if self.a is None or self.b is None:\n",
    "            raise ValueError('Model parameters not set!')\n",
    "        return 1.0 / (1 + math.e**(sample * self.a + self.b)[0, 0])\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.a, self.b = FilterSPAM.getModelParams(numpy.matrix(data), labels, len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PickledDataProcessing:\n",
    "    #Append new data to existing dictionary/frequency database\n",
    "    @staticmethod\n",
    "    def createDictionary(dictionary, frequency, files):\n",
    "        tmpDict = []\n",
    "        tmpFreq = []\n",
    "        tmpAppends = []\n",
    "\n",
    "        #Create small dict\n",
    "        for file in files:\n",
    "            for word in file.split(\" \"):\n",
    "                if word in tmpDict:\n",
    "                    tmpFreq[tmpDict.index(word)] += 1\n",
    "                else:\n",
    "                    tmpDict.append(word)\n",
    "                    tmpFreq.append(1)\n",
    "\n",
    "        #Merge old and new dict\n",
    "        for i in range(len(tmpDict)):\n",
    "            if tmpDict[i] in dictionary:\n",
    "                frequency[dictionary.index(tmpDict[i])] += tmpFreq[i]\n",
    "            else:\n",
    "                tmpAppends.append(word)\n",
    "                frequency.append(tmpFreq[i])\n",
    "        return dictionary + tmpAppends, frequency\n",
    "\n",
    "    #Expand the database from a given pickled file. Merge every mergeAfter messages.\n",
    "    @staticmethod\n",
    "    def crawlMails(dictionary, frequency, dump, mergeAfter = 10000):\n",
    "        i = 0\n",
    "        spam = pickle.load(open( dump, \"rb\" ))\n",
    "        files = []\n",
    "        for text in spam:\n",
    "            content = (Parser.stripHeaders(text)).lower()\n",
    "            files.append(content)\n",
    "            if i==mergeAfter:\n",
    "                i = -1\n",
    "                dictionary, frequency = PickledDataProcessing.createDictionary(dictionary, frequency, files)\n",
    "                del(files)\n",
    "                files = []\n",
    "                break\n",
    "            i+=1        \n",
    "        return dictionary, frequency\n",
    "    \n",
    "    #Load SPAM/HAM files from two pickled databases. Return them as an input data for classifier parsed with a given parser.\n",
    "    @staticmethod\n",
    "    def loadMails(parser, spamFile, hamFile, count = -1):\n",
    "        spam = []\n",
    "        msgs = []\n",
    "        \n",
    "        ctr = 0\n",
    "        print \"Load SPAM\"\n",
    "        for i in pickle.load(open( spamFile, \"rb\" )):\n",
    "            spam.append(parser.parseEmail(i))\n",
    "            if (count != -1):\n",
    "                if ctr == count:\n",
    "                    ctr = 0\n",
    "                    break\n",
    "                ctr += 1\n",
    "\n",
    "        print \"Load HAM\"\n",
    "        for i in pickle.load(open( hamFile, \"rb\" )):\n",
    "            msgs.append(parser.parseEmail(i))\n",
    "            if (count != -1):\n",
    "                if ctr == count:\n",
    "                    ctr = 0\n",
    "                    break\n",
    "                ctr += 1\n",
    "\n",
    "        return spam, msgs\n",
    "\n",
    "    #Cut the extremes off the dictionary\n",
    "    @staticmethod\n",
    "    def simplifyDictionary(dictionary, frequency, percentageUpperBound = 0.95, minOccurences = 200):\n",
    "        newDict = []\n",
    "        maximum = max(frequency)\n",
    "        for i in range(len(dictionary)):\n",
    "            if frequency[i] < maximum * percentageUpperBound and frequency[i] > minOccurences:\n",
    "                newDict.append(dictionary[i])\n",
    "        return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8242\n",
      "Load SPAM\n",
      "Load HAM\n",
      "DONE preprocessing\n",
      "[[ 3.85362574]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "-4.48312629543\n",
      "DONE learning\n"
     ]
    }
   ],
   "source": [
    "d, f = PickledDataProcessing.crawlMails([], [], \"SPAM.p\", 2000)\n",
    "d, f = PickledDataProcessing.crawlMails(d, f, \"HAM.p\", 2000)\n",
    "sim = PickledDataProcessing.simplifyDictionary(d, f, 0.995, 5)\n",
    "print len(sim)\n",
    "parser = Parser(sim)\n",
    "s, m = PickledDataProcessing.loadMails(parser, \"SPAM.p\", \"HAM.p\", 2000)\n",
    "print \"DONE preprocessing\"\n",
    "\n",
    "fil = FilterSPAM(s + m, [True] * len(s) + [False] * len(m))\n",
    "print fil.a\n",
    "print fil.b\n",
    "\n",
    "print \"DONE learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.85362574]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "-4.48312629543\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataPickling:\n",
    "    @staticmethod\n",
    "    def picklizeSPAM():  \n",
    "        msgs = []\n",
    "        for directory in os.listdir(\"./SPAM\"):\n",
    "            for filename in os.listdir(\"./SPAM/\"+directory):\n",
    "                with open(\"./SPAM/\"+directory+\"/\"+filename) as f:\n",
    "                    msgs.append(f.read().lower())\n",
    "            print directory + \" with total # of emails: \" + str(len(msgs))\n",
    "        pickle.dump( msgs, open( \"SPAM.p\", \"wb\" ))\n",
    "\n",
    "    @staticmethod\n",
    "    def picklizeEnron():  \n",
    "        msgs = []\n",
    "\n",
    "        for directory in os.listdir(\"./Enron\"):\n",
    "            if \"inbox\" not in os.listdir(\"./Enron/\"+directory):\n",
    "                continue\n",
    "            for filename in os.listdir(\"./Enron/\"+directory+\"/inbox\"):\n",
    "                try:\n",
    "                    with open(\"./Enron/\"+directory+\"/inbox/\"+filename) as f:\n",
    "                        msgs.append(f.read().lower())\n",
    "                except:\n",
    "                    None\n",
    "            print directory + \" with total # of emails: \" + str(len(msgs))\n",
    "        pickle.dump( msgs, open( \"HAM.p\", \"wb\" ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def picklizeHAM():\n",
    "        msgs = []\n",
    "        for filename in os.listdir(\"./HAM\"):\n",
    "            with open(\"./HAM/\"+filename) as f:\n",
    "                msgs.append(f.read().lower())\n",
    "        print \"total # of emails: \" + str(len(msgs))\n",
    "        pickle.dump( msgs, open( \"HAM.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52% of SPAM passed through filter\n",
      "1% of MESSAGES were filtered\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "i = 0\n",
    "for x in s:\n",
    "    test = fil.evaluate(x)\n",
    "    if not test < 1.0 / 2:\n",
    "        i += 1\n",
    "print str(100 * i / len(s)) + \"% of SPAM passed through filter\"\n",
    "\n",
    "i = 0\n",
    "for x in m:\n",
    "    test = fil.evaluate(x)\n",
    "    if test < 1.0 / 2:\n",
    "        i += 1\n",
    "print str(100 * i / len(m)) + \"% of MESSAGES were filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
